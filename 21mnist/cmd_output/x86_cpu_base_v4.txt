80624: open a log Tue Jan 31 17:06:22 2023
133210: verbose=4
140579: data-dir=data
146271: lr=1.000000
155933: epochs=1
161127: batch-size=64
166102: train-data-size=1
171271: test-data-size=0
176777: weight-seed=45678901234523
182195: dropout-seed-1=56789012345234
187098: dropout-seed-2=67890123452345
191989: grad-dbg=0
196844: algo=0
201736: algo_s=cpu_base
206612: cuda_algo=0
211485: log=mnist.log
227045: host=taulec
234517: USER=u22777
240035: PWD=/home/u22777/report_repo_hendrik/parallel-distributed/21mnist
245979: SLURM_SUBMIT_DIR undefined
251223: SLURM_SUBMIT_HOST undefined
256104: SLURM_JOB_NAME undefined
261320: SLURM_JOB_CPUS_PER_NODE undefined
266183: SLURM_NTASKS undefined
271143: SLURM_NPROCS undefined
276151: SLURM_JOB_ID undefined
281131: SLURM_JOBID undefined
286208: SLURM_NNODES undefined
291191: SLURM_JOB_NUM_NODES undefined
296196: SLURM_NODELIST undefined
301200: SLURM_JOB_PARTITION undefined
306255: SLURM_TASKS_PER_NODE undefined
311233: SLURM_JOB_NODELIST undefined
316163: CUDA_VISIBLE_DEVICES undefined
321056: GPU_DEVICE_ORDINAL undefined
326106: SLURM_CPUS_ON_NODE undefined
330913: SLURM_TASK_PID undefined
335804: SLURM_NODEID undefined
340717: SLURM_PROCID undefined
345569: SLURM_LOCALID undefined
350358: SLURM_JOB_UID undefined
355154: SLURM_JOB_USER undefined
360163: SLURM_JOB_GID undefined
364967: SLURMD_NODENAME undefined
370066: model building starts
82658609: model building ends
82669365: loading data from data
909202783: use 1 data items out of 60000
910203009: loading data from data
1029823691: use 0 data items out of 10000
1029997115: training starts
1029999405: Train Epoch 1 starts
1030013095: Train Epoch 1 batch 0 (samples 0 - 1) starts
1030015988: tensor<real, maxB, OC, H - K + 1, W - K + 1> &Convolution2D<64, 1, 28, 28, 3, 32>::forward(tensor<real, maxB, IC, H, W> &, int) [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: starts
1031478816: tensor<real, maxB, OC, H - K + 1, W - K + 1> &Convolution2D<64, 1, 28, 28, 3, 32>::forward(tensor<real, maxB, IC, H, W> &, int) [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: ends. took 1460197 nsec
1031481555: tensor<real, N0, N1, N2, N3> &Relu<64, 32, 26, 26>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 32, N2 = 26, N3 = 26]: starts
1031684466: tensor<real, N0, N1, N2, N3> &Relu<64, 32, 26, 26>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 32, N2 = 26, N3 = 26]: ends. took 201034 nsec
1031686069: tensor<real, maxB, OC, H - K + 1, W - K + 1> &Convolution2D<64, 32, 26, 26, 3, 64>::forward(tensor<real, maxB, IC, H, W> &, int) [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: starts
1104079222: tensor<real, maxB, OC, H - K + 1, W - K + 1> &Convolution2D<64, 32, 26, 26, 3, 64>::forward(tensor<real, maxB, IC, H, W> &, int) [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: ends. took 72391743 nsec
1104081902: tensor<real, N0, N1, N2, N3> &Relu<64, 64, 24, 24>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 64, N2 = 24, N3 = 24]: starts
1104438318: tensor<real, N0, N1, N2, N3> &Relu<64, 64, 24, 24>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 64, N2 = 24, N3 = 24]: ends. took 354738 nsec
1104440510: tensor<real, maxB, C, H / S, W / S> &MaxPooling2D<64, 64, 24, 24, 2>::forward(tensor<real, maxB, C, H, W> &, int) [maxB = 64, C = 64, H = 24, W = 24, S = 2]: starts
1104819238: tensor<real, maxB, C, H / S, W / S> &MaxPooling2D<64, 64, 24, 24, 2>::forward(tensor<real, maxB, C, H, W> &, int) [maxB = 64, C = 64, H = 24, W = 24, S = 2]: ends. took 377377 nsec
1104820740: tensor<real, N0, N1, N2, N3> &Dropout<64, 64, 12, 12>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 64, N2 = 12, N3 = 12]: starts
1104971638: tensor<real, N0, N1, N2, N3> &Dropout<64, 64, 12, 12>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 64, N2 = 12, N3 = 12]: ends. took 149694 nsec
1104972921: tensor<real, M, N> &Linear<64, 128, 64, 12, 12>::forward(tensor<real, M, K0, K1, K2> &, int) [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: starts
1115841483: tensor<real, M, N> &Linear<64, 128, 64, 12, 12>::forward(tensor<real, M, K0, K1, K2> &, int) [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: ends. took 10867237 nsec
1115864502: tensor<real, N0, N1, N2, N3> &Relu<64, 128, 1, 1>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: starts
1115869576: tensor<real, N0, N1, N2, N3> &Relu<64, 128, 1, 1>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: ends. took 3312 nsec
1115871663: tensor<real, N0, N1, N2, N3> &Dropout<64, 128, 1, 1>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: starts
1115877167: tensor<real, N0, N1, N2, N3> &Dropout<64, 128, 1, 1>::forward(tensor<real, N0, N1, N2, N3> &, int) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: ends. took 3944 nsec
1115878954: tensor<real, M, N> &Linear<64, 10, 128, 1, 1>::forward(tensor<real, M, K0, K1, K2> &, int) [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: starts
1115893042: tensor<real, M, N> &Linear<64, 10, 128, 1, 1>::forward(tensor<real, M, K0, K1, K2> &, int) [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: ends. took 12297 nsec
1115895062: tensor<real, maxB> &NLLSoftmax<64, 10>::forward(tensor<real, maxB, nC> &, tensor<idx_t, maxB> &, int) [maxB = 64, nC = 10]: starts
1115915992: tensor<real, maxB> &NLLSoftmax<64, 10>::forward(tensor<real, maxB, nC> &, tensor<idx_t, maxB> &, int) [maxB = 64, nC = 10]: ends. took 19296 nsec
1115917885: tensor<real, maxB, nC> &NLLSoftmax<64, 10>::backward(tensor<real, maxB> &, tensor<idx_t, maxB> &) [maxB = 64, nC = 10]: starts
1115919745: tensor<real, maxB, nC> &NLLSoftmax<64, 10>::backward(tensor<real, maxB> &, tensor<idx_t, maxB> &) [maxB = 64, nC = 10]: ends. took 552 nsec
1115921183: tensor<real, M, K0, K1, K2> &Linear<64, 10, 128, 1, 1>::backward(tensor<real, M, N> &) [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: starts
1115948872: tensor<real, M, K0, K1, K2> &Linear<64, 10, 128, 1, 1>::backward(tensor<real, M, N> &) [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: ends. took 26267 nsec
1115950303: tensor<real, N0, N1, N2, N3> &Dropout<64, 128, 1, 1>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: starts
1115955456: tensor<real, N0, N1, N2, N3> &Dropout<64, 128, 1, 1>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: ends. took 3827 nsec
1115956843: tensor<real, N0, N1, N2, N3> &Relu<64, 128, 1, 1>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: starts
1115961698: tensor<real, N0, N1, N2, N3> &Relu<64, 128, 1, 1>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 128, N2 = 1, N3 = 1]: ends. took 3528 nsec
1115963082: tensor<real, M, K0, K1, K2> &Linear<64, 128, 64, 12, 12>::backward(tensor<real, M, N> &) [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: starts
1135372141: tensor<real, M, K0, K1, K2> &Linear<64, 128, 64, 12, 12>::backward(tensor<real, M, N> &) [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: ends. took 19407642 nsec
1135378242: tensor<real, N0, N1, N2, N3> &Dropout<64, 64, 12, 12>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 64, N2 = 12, N3 = 12]: starts
1135539885: tensor<real, N0, N1, N2, N3> &Dropout<64, 64, 12, 12>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 64, N2 = 12, N3 = 12]: ends. took 160153 nsec
1135541459: tensor<real, maxB, C, H, W> &MaxPooling2D<64, 64, 24, 24, 2>::backward(tensor<real, maxB, C, H / S, W / S> &) [maxB = 64, C = 64, H = 24, W = 24, S = 2]: starts
1135810289: tensor<real, maxB, C, H, W> &MaxPooling2D<64, 64, 24, 24, 2>::backward(tensor<real, maxB, C, H / S, W / S> &) [maxB = 64, C = 64, H = 24, W = 24, S = 2]: ends. took 267524 nsec
1135811927: tensor<real, N0, N1, N2, N3> &Relu<64, 64, 24, 24>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 64, N2 = 24, N3 = 24]: starts
1136166063: tensor<real, N0, N1, N2, N3> &Relu<64, 64, 24, 24>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 64, N2 = 24, N3 = 24]: ends. took 352904 nsec
1136167824: tensor<real, maxB, IC, H, W> &Convolution2D<64, 32, 26, 26, 3, 64>::backward(tensor<real, maxB, OC, H - K + 1, W - K + 1> &) [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: starts
1301878119: tensor<real, maxB, IC, H, W> &Convolution2D<64, 32, 26, 26, 3, 64>::backward(tensor<real, maxB, OC, H - K + 1, W - K + 1> &) [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: ends. took 165699492 nsec
1301880980: tensor<real, N0, N1, N2, N3> &Relu<64, 32, 26, 26>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 32, N2 = 26, N3 = 26]: starts
1302093751: tensor<real, N0, N1, N2, N3> &Relu<64, 32, 26, 26>::backward(tensor<real, N0, N1, N2, N3> &) [N0 = 64, N1 = 32, N2 = 26, N3 = 26]: ends. took 211155 nsec
1302095981: tensor<real, maxB, IC, H, W> &Convolution2D<64, 1, 28, 28, 3, 32>::backward(tensor<real, maxB, OC, H - K + 1, W - K + 1> &) [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: starts
1305195918: tensor<real, maxB, IC, H, W> &Convolution2D<64, 1, 28, 28, 3, 32>::backward(tensor<real, maxB, OC, H - K + 1, W - K + 1> &) [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: ends. took 3098615 nsec
1305197838: void Convolution2D<64, 1, 28, 28, 3, 32>::update() [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: starts
1305231127: void Convolution2D<64, 1, 28, 28, 3, 32>::update() [maxB = 64, IC = 1, H = 28, W = 28, K = 3, OC = 32]: ends. took 31768 nsec
1305232792: void Convolution2D<64, 32, 26, 26, 3, 64>::update() [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: starts
1306697915: void Convolution2D<64, 32, 26, 26, 3, 64>::update() [maxB = 64, IC = 32, H = 26, W = 26, K = 3, OC = 64]: ends. took 1463477 nsec
1306700184: void Linear<64, 128, 64, 12, 12>::update() [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: starts
1394538040: void Linear<64, 128, 64, 12, 12>::update() [M = 64, N = 128, K0 = 64, K1 = 12, K2 = 12]: ends. took 87836331 nsec
1394544073: void Linear<64, 10, 128, 1, 1>::update() [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: starts
1394651738: void Linear<64, 10, 128, 1, 1>::update() [M = 64, N = 10, K0 = 128, K1 = 1, K2 = 1]: ends. took 106035 nsec
1394654105: sample 0 image 0 pred 6 truth 5
1394656194: Train Epoch: 1 [0/1 (0%)]	Loss: 2.286959
1394662060: Train Epoch 1 batch 0 (samples 0 - 1) ends
1394664061: Train Epoch 1 ends
1394665579: Test Epoch 1 starts
1394666731: Test Epoch 1 ends
1394668186: training ends
1394684399: close a log Tue Jan 31 17:06:23 2023
